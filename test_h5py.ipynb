{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_fenics(filename, dataset=\"concentration_0\"):\n",
    "    \"\"\"\n",
    "    Function used to read nodal values from H5 files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        String containing the filename for reading files in h5 (libMesh and EdgeCFD).\n",
    "    dataset : str\n",
    "        String containing the dataset desired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array : np.array\n",
    "        Numpy array containing nodal values.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as h5_file_input:\n",
    "        data_array = h5_file_input[\"concentration\"][\"concentration_0\"][\"vector\"][...]\n",
    "    return data_array\n",
    "\n",
    "def write_h5_fenics(filename, data_array):\n",
    "    \"\"\"\n",
    "    Function used to read nodal values from H5 files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        String containing the filename for reading files in h5 (libMesh and EdgeCFD).\n",
    "    dataset : str\n",
    "        String containing the dataset desired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array : np.array\n",
    "        Numpy array containing nodal values.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r+\") as h5_file_output:\n",
    "        h5_file_output[\"concentration\"][\"concentration_0\"][\"vector\"][...] = data_array\n",
    "    return \n",
    "\n",
    "def close_all_h5():\n",
    "    for obj in gc.get_objects():   # Browse through ALL objects\n",
    "        if isinstance(obj, h5py.File):   # Just HDF5 files\n",
    "            try:\n",
    "                obj.close()\n",
    "            except:\n",
    "                pass # Was already closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100\n",
      "2 99\n",
      "3 98\n",
      "4 97\n",
      "5 96\n",
      "6 95\n",
      "7 94\n",
      "8 93\n",
      "9 92\n",
      "10 91\n",
      "11 90\n",
      "12 89\n",
      "13 88\n",
      "14 87\n",
      "15 86\n",
      "16 85\n",
      "17 84\n",
      "18 83\n",
      "19 82\n",
      "20 81\n",
      "21 80\n",
      "22 79\n",
      "23 78\n",
      "24 77\n",
      "25 76\n",
      "26 75\n",
      "27 74\n",
      "28 73\n",
      "29 72\n",
      "30 71\n",
      "31 70\n",
      "32 69\n",
      "33 68\n",
      "34 67\n",
      "35 66\n",
      "36 65\n",
      "37 64\n",
      "38 63\n",
      "39 62\n",
      "40 61\n",
      "41 60\n",
      "42 59\n",
      "43 58\n",
      "44 57\n",
      "45 56\n",
      "46 55\n",
      "47 54\n",
      "48 53\n",
      "49 52\n",
      "50 51\n",
      "51 50\n",
      "52 49\n",
      "53 48\n",
      "54 47\n",
      "55 46\n",
      "56 45\n",
      "57 44\n",
      "58 43\n",
      "59 42\n",
      "60 41\n",
      "61 40\n",
      "62 39\n",
      "63 38\n",
      "64 37\n",
      "65 36\n",
      "66 35\n",
      "67 34\n",
      "68 33\n",
      "69 32\n",
      "70 31\n",
      "71 30\n",
      "72 29\n",
      "73 28\n",
      "74 27\n",
      "75 26\n",
      "76 25\n",
      "77 24\n",
      "78 23\n",
      "79 22\n",
      "80 21\n",
      "81 20\n",
      "82 19\n",
      "83 18\n",
      "84 17\n",
      "85 16\n",
      "86 15\n",
      "87 14\n",
      "88 13\n",
      "89 12\n",
      "90 11\n",
      "91 10\n",
      "92 9\n",
      "93 8\n",
      "94 7\n",
      "95 6\n",
      "96 5\n",
      "97 4\n",
      "98 3\n",
      "99 2\n",
      "100 1\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"results_parallel/\"\n",
    "output_dir = \"h5_changed_results/\"\n",
    "\n",
    "for i in range(1,101):\n",
    "    print(i, 101 - i)\n",
    "    data_array = read_h5_fenics(input_dir + f\"concentration_{101-i}.h5\")\n",
    "    write_h5_fenics(output_dir + f\"concentration_{i}.h5\", data_array) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output = \"h5_changed_results/concentration_1.h5\"\n",
    "filename_input = \"results_serial/concentration_100.h5\"\n",
    "\n",
    "\n",
    "h5_file_input = h5py.File(filename_input, \"r+\")\n",
    "h5_file_output = h5py.File(filename_output, \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = h5_file_input[\"concentration\"][\"concentration_0\"][\"vector\"]\n",
    "h5_file_output[\"concentration\"][\"concentration_0\"][\"vector\"][...] = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_input.close()\n",
    "h5_file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output = \"h5_changed_results/concentration_1.h5\"\n",
    "filename_input = \"results_serial/concentration_100.h5\"\n",
    "\n",
    "\n",
    "h5_file_input = h5py.File(filename_input, \"r+\")\n",
    "h5_file_output = h5py.File(filename_output, \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = h5_file_input[\"concentration\"][\"concentration_0\"][\"vector\"]\n",
    "data_2 = h5_file_output[\"concentration\"][\"concentration_0\"][\"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(data_1, data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_input.close()\n",
    "h5_file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_output = \"h5_changed_results/concentration_1.h5\"\n",
    "filename_input = \"results_serial/concentration_99.h5\"\n",
    "\n",
    "\n",
    "h5_file_input = h5py.File(filename_input, \"r+\")\n",
    "h5_file_output = h5py.File(filename_output, \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = h5_file_input[\"concentration\"][\"concentration_0\"][\"vector\"]\n",
    "data_2 = h5_file_output[\"concentration\"][\"concentration_0\"][\"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(data_1, data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_input.close()\n",
    "h5_file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88b72e7b56b60cae3aee6cc7dfd294b9153b4075dbb0c6cf56df3a9bf10333c"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('supg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
