{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fenics import *\n",
    "import h5py \n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_fenics(filename, dataset=\"concentration_0\"):\n",
    "    \"\"\"\n",
    "    Function used to read nodal values from H5 files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        String containing the filename for reading files in h5 (libMesh and EdgeCFD).\n",
    "    dataset : str\n",
    "        String containing the dataset desired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array : np.array\n",
    "        Numpy array containing nodal values.\n",
    "    \"\"\"\n",
    "    h5_file = h5py.File(filename, \"r\")\n",
    "    for key in h5_file.keys():\n",
    "        group = h5_file[key]\n",
    "        for key in group.keys():\n",
    "            data = group[(dataset)]\n",
    "    data_array = np.array(data[\"vector\"], copy=True)\n",
    "    h5_file.close()\n",
    "    return data_array\n",
    "\n",
    "def write_h5_fenics(filename, data_array dataset=\"concentration_0\"):\n",
    "    \"\"\"\n",
    "    Function used to read nodal values from H5 files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        String containing the filename for reading files in h5 (libMesh and EdgeCFD).\n",
    "    dataset : str\n",
    "        String containing the dataset desired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array : np.array\n",
    "        Numpy array containing nodal values.\n",
    "    \"\"\"\n",
    "    h5_file = h5py.File(filename, \"r+\")\n",
    "    h5_file[\"concentration\"][\"concentration_0\"][\"vector\"] = data_array\n",
    "    h5_file.close()\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_fenics(snapshot, t, out_c):\n",
    "    solution = Function(W)\n",
    "    solution.rename(\"concentration\", \"c/c0\")\n",
    "    solution.vector()[:] = np.squeeze(snapshot)\n",
    "    out_c << (solution, t)\n",
    "    #out_c.write_checkpoint(solution, \"conc\", t)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_C = f\"reconstruction_results_serial/concentration_reconstructed.pvd\" # NOME DO ARQUIVO DE SAÍDA\n",
    "#out_c = XDMFFile(FILE_C)\n",
    "out_c = File(FILE_C, \"compressed\")\n",
    "\n",
    "READ_PICKLE = False \n",
    "HEIGHT = 2.05\n",
    "WIDTH = 18.0\n",
    "NX = 700\n",
    "NY = 100\n",
    "\n",
    "comm = MPI.comm_world\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "parameters[\"form_compiler\"][\"optimize\"] = True\n",
    "parameters[\"form_compiler\"][\"cpp_optimize\"] = True\n",
    "\n",
    "\n",
    "mesh = RectangleMesh(Point(0.0, 0.0), Point(WIDTH, HEIGHT), NX, NY)\n",
    "\n",
    "P1 = FiniteElement(\"Lagrange\", mesh.ufl_cell(), 1)\n",
    "W = FunctionSpace(mesh, P1)\n",
    "\n",
    "if READ_PICKLE:\n",
    "    with open(\"pod_270_DL_16.pkl\", \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "else:\n",
    "    first_snapshot = read_h5_fenics(\"results_serial/concentration_1.h5\")\n",
    "    rows = first_snapshot.shape[0]\n",
    "    columns = 101\n",
    "    x = np.zeros((rows, columns))\n",
    "    x[:, 0] = np.squeeze(first_snapshot)\n",
    "    for i in range(1, columns):\n",
    "        data = read_h5_fenics(f\"results_serial/concentration_{i}.h5\")\n",
    "        x[:, i] = np.squeeze(data)\n",
    " \n",
    "\n",
    "for i in range(x.shape[1]): # LOOP POR TODOS OS VETORES APROXIMADOS PELO ROM\n",
    "    reconstruction = x[:, i] \n",
    "    insert_data_to_fenics(reconstruction, i, out_c) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"h5_changed_results/concentration_1.h5\"\n",
    "h5_file = h5py.File(filename, \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"concentration_1.h5\" (mode r+)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['concentration']>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"vector\": shape (70801, 1), type \"<f8\">"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_file[\"concentration\"][\"concentration_0\"][\"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88b72e7b56b60cae3aee6cc7dfd294b9153b4075dbb0c6cf56df3a9bf10333c"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('supg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
